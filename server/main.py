import sys
from pathlib import Path
from typing import Dict, Any, Optional
import os

# =========================
# PYTHONPATH ë³´ì • (í•„ìˆ˜)
# =========================
BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR))

# =========================
# MCP
# =========================
from mcp.server.fastmcp import FastMCP

from tools import (
    AINewsCollector,
    get_cached_news,
    AIAgentCatalog,
)

from tools.api_integrations import (
    get_trending_ai_models,
    search_models,
    get_latest_ai_research,
    get_all_updates,
)

from tools.realtime_collector import (
    get_realtime_rankings,
    recommend_model_for_task,
)

# MCP ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("AI Recommender MCP")

agent_catalog = AIAgentCatalog()

# =========================
# MCP Tools
# =========================

@mcp.tool()
def list_ai_agents(category: str = "all", subcategory: Optional[str] = None) -> Dict[str, Any]:
    """AI Agent ëª©ë¡ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return agent_catalog.list_agents(category, subcategory)

@mcp.tool()
def search_ai_agents(query: str) -> Dict[str, Any]:
    """í‚¤ì›Œë“œë¡œ AI Agentë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return agent_catalog.search_agents(query)

@mcp.tool()
def recommend_ai_agent(task: str, experience_level: str = "intermediate", budget: str = "any") -> Dict[str, Any]:
    """íŠ¹ì • ì‘ì—…ì— ë§ëŠ” AI Agentë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    return agent_catalog.recommend_for_task(task, experience_level, budget)

@mcp.tool()
async def get_ai_news(category: str = "all", limit: int = 10):
    """ìµœì‹  AI ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_cached_news(category, limit)

@mcp.tool()
async def get_trending_models(limit: int = 10):
    """íŠ¸ë Œë”© AI ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_trending_ai_models(limit)

@mcp.tool()
async def search_model_for_task(task: str):
    """ì‘ì—…ì— ë§ëŠ” ëª¨ë¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return await search_models(task)

@mcp.tool()
async def latest_ai_research(max_results: int = 10):
    """ìµœì‹  AI ì—°êµ¬ ë…¼ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_latest_ai_research(max_results)

@mcp.tool()
async def ai_overview():
    """AI ìƒíƒœê³„ ì¢…í•© ì—…ë°ì´íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_all_updates()

@mcp.tool()
async def realtime_model_rankings(benchmark: str = "artificial-analysis"):
    """ì‹¤ì‹œê°„ AI ëª¨ë¸ ìˆœìœ„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_realtime_rankings(benchmark)

@mcp.tool()
async def recommend_model(task: str):
    """ì‘ì—…ì— ìµœì í™”ëœ ëª¨ë¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    return await recommend_model_for_task(task)


# =========================
# Run
# =========================
if __name__ == "__main__":
    mode = os.getenv("MCP_MODE", "stdio")
    
    print(f"ğŸš€ Starting MCP Server in {mode} mode", file=sys.stderr)
    
    if mode == "sse":
        # ë¡œì»¬ SSE í…ŒìŠ¤íŠ¸ìš©
        port = int(os.getenv("PORT", 8000))
        print(f"ğŸ“¡ SSE server at http://localhost:{port}", file=sys.stderr)
        mcp.run(transport="sse", port=port)
    else:
        # stdio ëª¨ë“œ (MCP Inspectorìš©)
        print("ğŸ“Ÿ stdio mode - Connect with MCP Inspector", file=sys.stderr)
        mcp.run()