import os
from typing import Dict, Any

from mcp.server.fastmcp import FastMCP

# =============================
# tools import
# =============================
from tools import (
    AINewsCollector,
    get_cached_news,
    AIAgentCatalog,
)

from tools.api_integrations import (
    get_trending_ai_models,
    search_models,
    get_latest_ai_research,
    get_all_updates,
)

from tools.realtime_collector import (
    get_realtime_rankings,
    recommend_model_for_task,
)

# =============================
# MCP ì„œë²„ ìƒì„±
# =============================
mcp = FastMCP(
    name="AI Recommender MCP",
    description="AI ë„êµ¬, ì—ì´ì „íŠ¸, ëª¨ë¸, ë…¼ë¬¸, íŠ¸ë Œë“œë¥¼ ì¶”ì²œí•˜ëŠ” MCP ì„œë²„"
)

agent_catalog = AIAgentCatalog()
news_collector = AINewsCollector()

# =============================
# MCP tools ë“±ë¡
# =============================

@mcp.tool(
    name="list_ai_agents",
    description="ì¹´í…Œê³ ë¦¬ë³„ AI Agent ëª©ë¡ ì¡°íšŒ"
)
def list_ai_agents(category: str = "all", subcategory: str | None = None) -> Dict[str, Any]:
    return agent_catalog.list_agents(category, subcategory)


@mcp.tool(
    name="search_ai_agents",
    description="í‚¤ì›Œë“œ ê¸°ë°˜ AI Agent ê²€ìƒ‰"
)
def search_ai_agents(query: str) -> Dict[str, Any]:
    return agent_catalog.search_agents(query)


@mcp.tool(
    name="recommend_ai_agent",
    description="ì‘ì—…, ê²½í—˜ ìˆ˜ì¤€, ì˜ˆì‚° ê¸°ë°˜ AI Agent ì¶”ì²œ"
)
def recommend_ai_agent(task: str, experience_level: str, budget: str) -> Dict[str, Any]:
    return agent_catalog.recommend_for_task(task, experience_level, budget)


@mcp.tool(
    name="get_ai_news",
    description="ìµœì‹  AI ë‰´ìŠ¤ ë° ì—°êµ¬, í”„ë¡œì íŠ¸ ì¡°íšŒ"
)
async def get_ai_news(category: str = "all", limit: int = 10) -> Dict[str, Any]:
    return await get_cached_news(category, limit)


@mcp.tool(
    name="get_trending_models",
    description="í˜„ì¬ íŠ¸ë Œë”© ì¤‘ì¸ AI ëª¨ë¸ ì¡°íšŒ"
)
async def get_trending_models(limit: int = 10):
    return await get_trending_ai_models(limit)


@mcp.tool(
    name="search_model_for_task",
    description="ì‘ì—… ì„¤ëª… ê¸°ë°˜ AI ëª¨ë¸ ê²€ìƒ‰"
)
async def search_model_for_task(task: str):
    return await search_models(task)


@mcp.tool(
    name="latest_ai_research",
    description="ìµœì‹  AI ì—°êµ¬ ë…¼ë¬¸ ì¡°íšŒ"
)
async def latest_ai_research(limit: int = 10):
    return await get_latest_ai_research(limit)


@mcp.tool(
    name="ai_overview",
    description="ëª¨ë¸, í”„ë¡œì íŠ¸, ë…¼ë¬¸ ì¢…í•© AI ì—…ë°ì´íŠ¸"
)
async def ai_overview():
    return await get_all_updates()


@mcp.tool(
    name="realtime_model_rankings",
    description="ì‹¤ì‹œê°„ AI ëª¨ë¸ ë­í‚¹ ì¡°íšŒ"
)
async def realtime_model_rankings(benchmark: str = "artificial-analysis"):
    return await get_realtime_rankings(benchmark)


@mcp.tool(
    name="recommend_model",
    description="ì‘ì—…ì— ê°€ì¥ ì í•©í•œ AI ëª¨ë¸ ì¶”ì²œ"
)
async def recommend_model(task: str):
    return await recommend_model_for_task(task)

# =============================
# ì‹¤í–‰ë¶€ (ì¤‘ìš”)
# =============================
if __name__ == "__main__":
    mode = os.getenv("MCP_MODE", "http")

    if mode == "stdio":
        # ğŸ”¹ ë¡œì»¬ / Inspectorìš©
        mcp.run()
    else:
        # ğŸ”¹ Koyeb / PlayMCPìš©
        port = int(os.environ.get("PORT", 8000))
        mcp.run(
            transport="http",
            host="0.0.0.0",
            port=port,
            path="/mcp"
        )
