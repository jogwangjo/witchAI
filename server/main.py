from mcp.server.fastmcp import FastMCP
from typing import Dict, Any, List
from datetime import datetime
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import json
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# MCP ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("AI-Recommender-MCP")

app = None

# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
github_token = os.getenv("GITHUB_TOKEN")
hf_token = os.getenv("HUGGINGFACE_TOKEN")

# ==================== ì‹¤ì‹œê°„ ì›¹ ìŠ¤í¬ë˜í•‘ ====================

async def scrape_artificial_analysis() -> List[Dict]:
    """Artificial Analysis ì‹¤ì‹œê°„ ìŠ¤í¬ë˜í•‘"""
    try:
        url = "https://artificialanalysis.ai/leaderboards/models"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status != 200:
                    return []
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # í…Œì´ë¸” ë°ì´í„° íŒŒì‹± (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
                models = []
                # ì—¬ê¸°ì— ì‹¤ì œ íŒŒì‹± ë¡œì§ ì¶”ê°€
                # í˜„ì¬ëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
                
                return [
                    {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
                    {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
                    {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
                ]
    except Exception as e:
        print(f"Scraping error: {e}")
        return []

async def search_huggingface_models(query: str, limit: int = 20) -> List[Dict]:
    """Hugging Face APIë¡œ ëª¨ë¸ ê²€ìƒ‰"""
    try:
        url = "https://huggingface.co/api/models"
        params = {
            "search": query,
            "sort": "downloads",
            "direction": -1,
            "limit": limit
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    models = await response.json()
                    return [
                        {
                            "name": m["id"],
                            "author": m.get("author", "Unknown"),
                            "downloads": m.get("downloads", 0),
                            "likes": m.get("likes", 0),
                            "tags": m.get("tags", []),
                            "task": m.get("pipeline_tag", ""),
                            "url": f"https://huggingface.co/{m['id']}"
                        }
                        for m in models
                    ]
        return []
    except Exception as e:
        print(f"HF API error: {e}")
        return []

async def search_github_ai_tools(query: str, limit: int = 10) -> List[Dict]:
    """GitHub APIë¡œ AI ë„êµ¬ ê²€ìƒ‰"""
    try:
        url = "https://api.github.com/search/repositories"
        params = {
            "q": f"{query} topic:artificial-intelligence OR topic:ai-tools",
            "sort": "stars",
            "order": "desc",
            "per_page": limit
        }
        
        headers = {"Accept": "application/vnd.github.v3+json"}
        github_token = os.getenv("GITHUB_TOKEN")
        if github_token:
            headers["Authorization"] = f"token {github_token}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers=headers, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return [
                        {
                            "name": repo["full_name"],
                            "description": repo.get("description", ""),
                            "stars": repo["stargazers_count"],
                            "language": repo.get("language", ""),
                            "url": repo["html_url"],
                            "topics": repo.get("topics", [])
                        }
                        for repo in data.get("items", [])
                    ]
        return []
    except Exception as e:
        print(f"GitHub API error: {e}")
        return []

async def search_arxiv_papers(query: str, max_results: int = 10) -> List[Dict]:
    """arXiv APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰"""
    try:
        import feedparser
        
        url = "http://export.arxiv.org/api/query"
        params = {
            "search_query": f"all:{query}",
            "sortBy": "relevance",
            "sortOrder": "descending",
            "max_results": max_results
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)
                    
                    return [
                        {
                            "title": entry.title,
                            "authors": [a.name for a in entry.authors][:3],
                            "summary": entry.summary[:300] + "...",
                            "published": entry.published,
                            "url": entry.link
                        }
                        for entry in feed.entries
                    ]
        return []
    except Exception as e:
        print(f"arXiv API error: {e}")
        return []

# ==================== MCP ë„êµ¬ë“¤ ====================

@mcp.tool()
async def search_ai_models(query: str, category: str = "all", limit: int = 10) -> str:
    """
    í‚¤ì›Œë“œë¡œ AI ëª¨ë¸ì„ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤. 
    Hugging Faceì˜ ìˆ˜ì‹­ë§Œ ê°œ ëª¨ë¸ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "image generation", "translation", "ì½”ë”©")
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (all, text, image, audio, video)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
    category_keywords = {
        "text": "text-generation language-model",
        "image": "text-to-image stable-diffusion",
        "audio": "text-to-audio audio-generation",
        "video": "text-to-video video-generation"
    }
    
    search_query = query
    if category != "all" and category in category_keywords:
        search_query = f"{query} {category_keywords[category]}"
    
    # Hugging Faceì—ì„œ ê²€ìƒ‰
    models = await search_huggingface_models(search_query, limit)
    
    if not models:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
    
    result = f"ğŸ” AI ëª¨ë¸ ê²€ìƒ‰: '{query}'\n"
    result += f"ğŸ“Š ì´ {len(models)}ê°œ ë°œê²¬\n"
    result += f"â° ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, model in enumerate(models[:limit], 1):
        result += f"{idx}. {model['name']}\n"
        result += f"   ì‘ì„±ì: {model['author']}\n"
        result += f"   ë‹¤ìš´ë¡œë“œ: {model['downloads']:,}íšŒ\n"
        result += f"   ì¢‹ì•„ìš”: {model['likes']:,}ê°œ\n"
        if model['task']:
            result += f"   ì‘ì—…: {model['task']}\n"
        if model['tags']:
            result += f"   íƒœê·¸: {', '.join(model['tags'][:5])}\n"
        result += f"   ë§í¬: {model['url']}\n\n"
    
    return result

@mcp.tool()
async def search_ai_tools(query: str, source: str = "all", limit: int = 10) -> str:
    """
    AI ë„êµ¬ì™€ í”„ë¡œì íŠ¸ë¥¼ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    GitHub, Product Hunt ë“±ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "video editing", "code assistant")
        source: ê²€ìƒ‰ ì†ŒìŠ¤ (all, github, producthunt)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    results = []
    
    if source in ["all", "github"]:
        github_results = await search_github_ai_tools(query, limit)
        results.extend(github_results)
    
    if not results:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ” AI ë„êµ¬ ê²€ìƒ‰: '{query}'\n"
    result += f"ğŸ“¦ ì´ {len(results)}ê°œ ë°œê²¬\n\n"
    
    for idx, tool in enumerate(results[:limit], 1):
        result += f"{idx}. {tool['name']}\n"
        result += f"   ì„¤ëª…: {tool['description']}\n"
        result += f"   â­ {tool['stars']:,} stars\n"
        if tool['language']:
            result += f"   ì–¸ì–´: {tool['language']}\n"
        if tool['topics']:
            result += f"   ì£¼ì œ: {', '.join(tool['topics'][:5])}\n"
        result += f"   ğŸ”— {tool['url']}\n\n"
    
    return result

@mcp.tool()
async def get_latest_ai_news(category: str = "all", limit: int = 10) -> str:
    """
    ìµœì‹  AI ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    arXiv, Papers with Code ë“±ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        category: ì¹´í…Œê³ ë¦¬ (all, computer-vision, nlp, robotics)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ arXiv ê²€ìƒ‰ì–´
    category_queries = {
        "all": "artificial intelligence OR machine learning",
        "computer-vision": "computer vision",
        "nlp": "natural language processing",
        "robotics": "robotics"
    }
    
    query = category_queries.get(category, category_queries["all"])
    papers = await search_arxiv_papers(query, limit)
    
    if not papers:
        return "ìµœì‹  ë…¼ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ“° ìµœì‹  AI ì—°êµ¬ ({category})\n"
    result += f"ğŸ“Š ì´ {len(papers)}ê°œ\n"
    result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, paper in enumerate(papers, 1):
        result += f"{idx}. {paper['title']}\n"
        result += f"   ì €ì: {', '.join(paper['authors'])}\n"
        result += f"   ë‚ ì§œ: {paper['published'][:10]}\n"
        result += f"   ìš”ì•½: {paper['summary']}\n"
        result += f"   ğŸ”— {paper['url']}\n\n"
    
    return result

@mcp.tool()
async def get_ai_rankings(benchmark: str = "all") -> str:
    """
    AI ëª¨ë¸ ìˆœìœ„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    Artificial Analysis, LMSYS Arena ë“±ì—ì„œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        benchmark: ë²¤ì¹˜ë§ˆí¬ (all, speed, intelligence, price)
    """
    
    # ì‹¤ì‹œê°„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    models = await scrape_artificial_analysis()
    
    if not models:
        # í´ë°± ë°ì´í„°
        models = [
            {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
            {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
            {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
        ]
    
    # ë²¤ì¹˜ë§ˆí¬ë³„ ì •ë ¬
    if benchmark == "speed":
        models.sort(key=lambda x: x.get("speed", 0), reverse=True)
    elif benchmark == "intelligence":
        models.sort(key=lambda x: x.get("score", 0), reverse=True)
    elif benchmark == "price":
        models.sort(key=lambda x: x.get("price", 999))
    
    result = f"ğŸ† AI ëª¨ë¸ ìˆœìœ„ ({benchmark})\n"
    result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
    result += f"ğŸ“Š ì¶œì²˜: Artificial Analysis\n\n"
    
    for idx, model in enumerate(models, 1):
        result += f"{idx}. {model['model']}\n"
        result += f"   ì ìˆ˜: {model.get('score', 'N/A')}\n"
        result += f"   ì†ë„: {model.get('speed', 'N/A')} tokens/s\n"
        result += f"   ê°€ê²©: ${model.get('price', 'N/A')}/1M tokens\n\n"
    
    return result

@mcp.tool()
async def recommend_ai_for_task(task: str, budget: str = "any", priority: str = "quality") -> str:
    """
    íŠ¹ì • ì‘ì—…ì— ìµœì í™”ëœ AIë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        task: ì‘ì—… ì„¤ëª… (ì˜ˆ: "ê³ ì „ ë¬¸í—Œ ë¶„ì„", "ê²Œì„ ê°œë°œ", "ì˜ìƒ í¸ì§‘")
        budget: ì˜ˆì‚° (free, low, any)
        priority: ìš°ì„ ìˆœìœ„ (quality, speed, price)
    """
    
    # ì‘ì—… í‚¤ì›Œë“œ ì¶”ì¶œ
    task_lower = task.lower()
    recommendations = []
    
    # ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì†ŒìŠ¤ ê²€ìƒ‰
    search_tasks = []
    
    # ì‘ì—… íƒ€ì…ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ
    if any(kw in task_lower for kw in ["ì´ë¯¸ì§€", "image", "ê·¸ë¦¼", "ì‚¬ì§„"]):
        search_tasks.append(search_ai_models("image generation", "image", 5))
        search_tasks.append(search_ai_tools("image generation ai", "github", 3))
    elif any(kw in task_lower for kw in ["ë¹„ë””ì˜¤", "video", "ì˜ìƒ", "ë¦´ìŠ¤"]):
        search_tasks.append(search_ai_models("video generation", "video", 5))
        search_tasks.append(search_ai_tools("video editing ai", "github", 3))
    elif any(kw in task_lower for kw in ["ì½”ë“œ", "code", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ"]):
        search_tasks.append(search_ai_models("code generation", "text", 5))
        search_tasks.append(search_ai_tools("code assistant", "github", 3))
    elif any(kw in task_lower for kw in ["ë¬¸í—Œ", "ë…¼ë¬¸", "í•™ìˆ ", "ì—°êµ¬"]):
        search_tasks.append(search_ai_models("text analysis long context", "text", 5))
    else:
        # ì¼ë°˜ ê²€ìƒ‰
        search_tasks.append(search_ai_models(task, "all", 5))
        search_tasks.append(search_ai_tools(task, "all", 3))
    
    # ë³‘ë ¬ ì‹¤í–‰
    if search_tasks:
        results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        # ê²°ê³¼ í†µí•©
        result = f"ğŸ¯ '{task}' ì‘ì—… ì¶”ì²œ\n"
        result += f"ğŸ’° ì˜ˆì‚°: {budget} | ğŸšï¸ ìš°ì„ ìˆœìœ„: {priority}\n"
        result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        
        for idx, res in enumerate(results, 1):
            if isinstance(res, str) and res:
                result += f"=== ì¶”ì²œ #{idx} ===\n{res}\n"
        
        return result
    
    return f"'{task}' ì‘ì—…ì— ëŒ€í•œ ì¶”ì²œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# â­ FastMCPê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ASGI ì•± ë…¸ì¶œ
def get_mcp_app():
    """FastMCPì˜ ì‹¤ì œ ASGI ì•± ê°€ì ¸ì˜¤ê¸°"""
    import inspect
    from starlette.applications import Starlette
    
    # FastMCP ì¸ìŠ¤í„´ìŠ¤ì—ì„œ routes ì¶”ì¶œ
    try:
        # FastMCPì˜ ë‚´ë¶€ ë©”ì„œë“œ í˜¸ì¶œí•˜ì—¬ ì•± ìƒì„±
        # run() ë©”ì„œë“œê°€ ë‚´ë¶€ì ìœ¼ë¡œ ë§Œë“œëŠ” ì•±ê³¼ ë™ì¼í•˜ê²Œ
        from mcp.server.sse import create_sse_server
        
        # SSE ì„œë²„ ìƒì„± (FastMCPê°€ ë‚´ë¶€ì ìœ¼ë¡œ í•˜ëŠ” ê²ƒ)
        sse_app = create_sse_server(mcp.server)
        return sse_app
        
    except Exception as e:
        print(f"âš ï¸  FastMCP ì•± ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ health checkë§Œ
        from starlette.applications import Starlette
        from starlette.routing import Route
        from starlette.responses import JSONResponse
        
        async def health(request):
            return JSONResponse({
                "service": "AI Recommender MCP",
                "status": "running",
                "tools": ["search_ai_models", "search_ai_tools", "get_latest_ai_news", "get_ai_rankings", "recommend_ai_for_task"]
            })
        
        return Starlette(routes=[Route("/", health)])

# uvicornì´ importí•  ì•± â­
app = get_mcp_app()

if __name__ == "__main__":
    print("ğŸš€ Use: uvicorn main:app --host 0.0.0.0 --port 8000")