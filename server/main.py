from mcp.server.fastmcp import FastMCP
from typing import Dict, Any, List
from datetime import datetime
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import json
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# MCP ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("AI-Recommender-MCP")

# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
github_token = os.getenv("GITHUB_TOKEN")
hf_token = os.getenv("HUGGINGFACE_TOKEN")

# ==================== ì‹¤ì‹œê°„ ì›¹ ìŠ¤í¬ë˜í•‘ ====================

async def scrape_artificial_analysis() -> List[Dict]:
    """Artificial Analysis ì‹¤ì‹œê°„ ìŠ¤í¬ë˜í•‘"""
    try:
        url = "https://artificialanalysis.ai/leaderboards/models"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status != 200:
                    return []
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # í…Œì´ë¸” ë°ì´í„° íŒŒì‹± (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
                models = []
                # ì—¬ê¸°ì— ì‹¤ì œ íŒŒì‹± ë¡œì§ ì¶”ê°€
                # í˜„ì¬ëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
                
                return [
                    {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
                    {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
                    {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
                ]
    except Exception as e:
        print(f"Scraping error: {e}")
        return []

async def search_huggingface_models(query: str, limit: int = 20) -> List[Dict]:
    """Hugging Face APIë¡œ ëª¨ë¸ ê²€ìƒ‰"""
    try:
        url = "https://huggingface.co/api/models"
        params = {
            "search": query,
            "sort": "downloads",
            "direction": -1,
            "limit": limit
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    models = await response.json()
                    return [
                        {
                            "name": m["id"],
                            "author": m.get("author", "Unknown"),
                            "downloads": m.get("downloads", 0),
                            "likes": m.get("likes", 0),
                            "tags": m.get("tags", []),
                            "task": m.get("pipeline_tag", ""),
                            "url": f"https://huggingface.co/{m['id']}"
                        }
                        for m in models
                    ]
        return []
    except Exception as e:
        print(f"HF API error: {e}")
        return []

async def search_github_ai_tools(query: str, limit: int = 10) -> List[Dict]:
    """GitHub APIë¡œ AI ë„êµ¬ ê²€ìƒ‰"""
    try:
        url = "https://api.github.com/search/repositories"
        params = {
            "q": f"{query} topic:artificial-intelligence OR topic:ai-tools",
            "sort": "stars",
            "order": "desc",
            "per_page": limit
        }
        
        headers = {"Accept": "application/vnd.github.v3+json"}
        github_token = os.getenv("GITHUB_TOKEN")
        if github_token:
            headers["Authorization"] = f"token {github_token}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers=headers, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return [
                        {
                            "name": repo["full_name"],
                            "description": repo.get("description", ""),
                            "stars": repo["stargazers_count"],
                            "language": repo.get("language", ""),
                            "url": repo["html_url"],
                            "topics": repo.get("topics", [])
                        }
                        for repo in data.get("items", [])
                    ]
        return []
    except Exception as e:
        print(f"GitHub API error: {e}")
        return []

async def search_arxiv_papers(query: str, max_results: int = 10) -> List[Dict]:
    """arXiv APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰"""
    try:
        import feedparser
        
        url = "http://export.arxiv.org/api/query"
        params = {
            "search_query": f"all:{query}",
            "sortBy": "relevance",
            "sortOrder": "descending",
            "max_results": max_results
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)
                    
                    return [
                        {
                            "title": entry.title,
                            "authors": [a.name for a in entry.authors][:3],
                            "summary": entry.summary[:300] + "...",
                            "published": entry.published,
                            "url": entry.link
                        }
                        for entry in feed.entries
                    ]
        return []
    except Exception as e:
        print(f"arXiv API error: {e}")
        return []

# ==================== MCP ë„êµ¬ë“¤ ====================

@mcp.tool()
async def search_ai_models(query: str, category: str = "all", limit: int = 10) -> str:
    """
    í‚¤ì›Œë“œë¡œ AI ëª¨ë¸ì„ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤. 
    Hugging Faceì˜ ìˆ˜ì‹­ë§Œ ê°œ ëª¨ë¸ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "image generation", "translation", "ì½”ë”©")
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (all, text, image, audio, video)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
    category_keywords = {
        "text": "text-generation language-model",
        "image": "text-to-image stable-diffusion",
        "audio": "text-to-audio audio-generation",
        "video": "text-to-video video-generation"
    }
    
    search_query = query
    if category != "all" and category in category_keywords:
        search_query = f"{query} {category_keywords[category]}"
    
    # Hugging Faceì—ì„œ ê²€ìƒ‰
    models = await search_huggingface_models(search_query, limit)
    
    if not models:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
    
    result = f"ğŸ” AI ëª¨ë¸ ê²€ìƒ‰: '{query}'\n"
    result += f"ğŸ“Š ì´ {len(models)}ê°œ ë°œê²¬\n"
    result += f"â° ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, model in enumerate(models[:limit], 1):
        result += f"{idx}. {model['name']}\n"
        result += f"   ì‘ì„±ì: {model['author']}\n"
        result += f"   ë‹¤ìš´ë¡œë“œ: {model['downloads']:,}íšŒ\n"
        result += f"   ì¢‹ì•„ìš”: {model['likes']:,}ê°œ\n"
        if model['task']:
            result += f"   ì‘ì—…: {model['task']}\n"
        if model['tags']:
            result += f"   íƒœê·¸: {', '.join(model['tags'][:5])}\n"
        result += f"   ë§í¬: {model['url']}\n\n"
    
    return result

@mcp.tool()
async def search_ai_tools(query: str, source: str = "all", limit: int = 10) -> str:
    """
    AI ë„êµ¬ì™€ í”„ë¡œì íŠ¸ë¥¼ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    GitHub, Product Hunt ë“±ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "video editing", "code assistant")
        source: ê²€ìƒ‰ ì†ŒìŠ¤ (all, github, producthunt)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    results = []
    
    if source in ["all", "github"]:
        github_results = await search_github_ai_tools(query, limit)
        results.extend(github_results)
    
    if not results:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ” AI ë„êµ¬ ê²€ìƒ‰: '{query}'\n"
    result += f"ğŸ“¦ ì´ {len(results)}ê°œ ë°œê²¬\n\n"
    
    for idx, tool in enumerate(results[:limit], 1):
        result += f"{idx}. {tool['name']}\n"
        result += f"   ì„¤ëª…: {tool['description']}\n"
        result += f"   â­ {tool['stars']:,} stars\n"
        if tool['language']:
            result += f"   ì–¸ì–´: {tool['language']}\n"
        if tool['topics']:
            result += f"   ì£¼ì œ: {', '.join(tool['topics'][:5])}\n"
        result += f"   ğŸ”— {tool['url']}\n\n"
    
    return result

@mcp.tool()
async def get_latest_ai_news(category: str = "all", limit: int = 10) -> str:
    """
    ìµœì‹  AI ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    arXiv, Papers with Code ë“±ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        category: ì¹´í…Œê³ ë¦¬ (all, computer-vision, nlp, robotics)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    
    # ì¹´í…Œê³ ë¦¬ë³„ arXiv ê²€ìƒ‰ì–´
    category_queries = {
        "all": "artificial intelligence OR machine learning",
        "computer-vision": "computer vision",
        "nlp": "natural language processing",
        "robotics": "robotics"
    }
    
    query = category_queries.get(category, category_queries["all"])
    papers = await search_arxiv_papers(query, limit)
    
    if not papers:
        return "ìµœì‹  ë…¼ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ“° ìµœì‹  AI ì—°êµ¬ ({category})\n"
    result += f"ğŸ“Š ì´ {len(papers)}ê°œ\n"
    result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, paper in enumerate(papers, 1):
        result += f"{idx}. {paper['title']}\n"
        result += f"   ì €ì: {', '.join(paper['authors'])}\n"
        result += f"   ë‚ ì§œ: {paper['published'][:10]}\n"
        result += f"   ìš”ì•½: {paper['summary']}\n"
        result += f"   ğŸ”— {paper['url']}\n\n"
    
    return result

@mcp.tool()
async def get_ai_rankings(benchmark: str = "all") -> str:
    """
    AI ëª¨ë¸ ìˆœìœ„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    Artificial Analysis, LMSYS Arena ë“±ì—ì„œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        benchmark: ë²¤ì¹˜ë§ˆí¬ (all, speed, intelligence, price)
    """
    
    # ì‹¤ì‹œê°„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    models = await scrape_artificial_analysis()
    
    if not models:
        # í´ë°± ë°ì´í„°
        models = [
            {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
            {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
            {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
        ]
    
    # ë²¤ì¹˜ë§ˆí¬ë³„ ì •ë ¬
    if benchmark == "speed":
        models.sort(key=lambda x: x.get("speed", 0), reverse=True)
    elif benchmark == "intelligence":
        models.sort(key=lambda x: x.get("score", 0), reverse=True)
    elif benchmark == "price":
        models.sort(key=lambda x: x.get("price", 999))
    
    result = f"ğŸ† AI ëª¨ë¸ ìˆœìœ„ ({benchmark})\n"
    result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
    result += f"ğŸ“Š ì¶œì²˜: Artificial Analysis\n\n"
    
    for idx, model in enumerate(models, 1):
        result += f"{idx}. {model['model']}\n"
        result += f"   ì ìˆ˜: {model.get('score', 'N/A')}\n"
        result += f"   ì†ë„: {model.get('speed', 'N/A')} tokens/s\n"
        result += f"   ê°€ê²©: ${model.get('price', 'N/A')}/1M tokens\n\n"
    
    return result

@mcp.tool()
async def recommend_ai_for_task(task: str, budget: str = "any", priority: str = "quality") -> str:
    """
    íŠ¹ì • ì‘ì—…ì— ìµœì í™”ëœ AIë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        task: ì‘ì—… ì„¤ëª… (ì˜ˆ: "ê³ ì „ ë¬¸í—Œ ë¶„ì„", "ê²Œì„ ê°œë°œ", "ì˜ìƒ í¸ì§‘")
        budget: ì˜ˆì‚° (free, low, any)
        priority: ìš°ì„ ìˆœìœ„ (quality, speed, price)
    """
    
    # ì‘ì—… í‚¤ì›Œë“œ ì¶”ì¶œ
    task_lower = task.lower()
    recommendations = []
    
    # ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì†ŒìŠ¤ ê²€ìƒ‰
    search_tasks = []
    
    # ì‘ì—… íƒ€ì…ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ
    if any(kw in task_lower for kw in ["ì´ë¯¸ì§€", "image", "ê·¸ë¦¼", "ì‚¬ì§„"]):
        search_tasks.append(search_ai_models("image generation", "image", 5))
        search_tasks.append(search_ai_tools("image generation ai", "github", 3))
    elif any(kw in task_lower for kw in ["ë¹„ë””ì˜¤", "video", "ì˜ìƒ", "ë¦´ìŠ¤"]):
        search_tasks.append(search_ai_models("video generation", "video", 5))
        search_tasks.append(search_ai_tools("video editing ai", "github", 3))
    elif any(kw in task_lower for kw in ["ì½”ë“œ", "code", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ"]):
        search_tasks.append(search_ai_models("code generation", "text", 5))
        search_tasks.append(search_ai_tools("code assistant", "github", 3))
    elif any(kw in task_lower for kw in ["ë¬¸í—Œ", "ë…¼ë¬¸", "í•™ìˆ ", "ì—°êµ¬"]):
        search_tasks.append(search_ai_models("text analysis long context", "text", 5))
    else:
        # ì¼ë°˜ ê²€ìƒ‰
        search_tasks.append(search_ai_models(task, "all", 5))
        search_tasks.append(search_ai_tools(task, "all", 3))
    
    # ë³‘ë ¬ ì‹¤í–‰
    if search_tasks:
        results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        # ê²°ê³¼ í†µí•©
        result = f"ğŸ¯ '{task}' ì‘ì—… ì¶”ì²œ\n"
        result += f"ğŸ’° ì˜ˆì‚°: {budget} | ğŸšï¸ ìš°ì„ ìˆœìœ„: {priority}\n"
        result += f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        
        for idx, res in enumerate(results, 1):
            if isinstance(res, str) and res:
                result += f"=== ì¶”ì²œ #{idx} ===\n{res}\n"
        
        return result
    
    return f"'{task}' ì‘ì—…ì— ëŒ€í•œ ì¶”ì²œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ==================== HTTP ì„œë²„ (Koyebìš©) ====================

def get_mcp_app():
    """MCP í”„ë¡œí† ì½œ í˜¸í™˜ ASGI ì•±"""
    from starlette.applications import Starlette
    from starlette.routing import Route
    from starlette.responses import StreamingResponse, JSONResponse
    from starlette.requests import Request
    import json
    
    async def sse_endpoint(request: Request):
        """SSE ì—”ë“œí¬ì¸íŠ¸ - MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        
        async def event_generator():
            # SSE ì´ˆê¸°í™”
            yield 'data: {"jsonrpc":"2.0","method":"notifications/initialized"}\n\n'
            
            # Keep-alive
            try:
                while True:
                    await asyncio.sleep(30)
                    yield ': keepalive\n\n'
            except asyncio.CancelledError:
                pass
        
        return StreamingResponse(
            event_generator(),
            media_type='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Content-Type': 'text/event-stream',
                'X-Accel-Buffering': 'no',
            }
        )
    
    async def message_endpoint(request: Request):
        """MCP ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            body = await request.json()
            
            # MCP ìš”ì²­ ì²˜ë¦¬
            if body.get('method') == 'tools/list':
                # ë„êµ¬ ëª©ë¡ ë°˜í™˜
                return JSONResponse({
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "result": {
                        "tools": [
                            {
                                "name": "search_ai_models",
                                "description": "Hugging Faceì—ì„œ AI ëª¨ë¸ ê²€ìƒ‰",
                                "inputSchema": {
                                    "type": "object",
                                    "properties": {
                                        "query": {"type": "string"},
                                        "category": {"type": "string"},
                                        "limit": {"type": "integer"}
                                    }
                                }
                            },
                            {
                                "name": "search_ai_tools",
                                "description": "GitHubì—ì„œ AI ë„êµ¬ ê²€ìƒ‰",
                                "inputSchema": {
                                    "type": "object",
                                    "properties": {
                                        "query": {"type": "string"},
                                        "source": {"type": "string"},
                                        "limit": {"type": "integer"}
                                    }
                                }
                            },
                            {
                                "name": "get_latest_ai_news",
                                "description": "ìµœì‹  AI ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°",
                                "inputSchema": {
                                    "type": "object",
                                    "properties": {
                                        "category": {"type": "string"},
                                        "limit": {"type": "integer"}
                                    }
                                }
                            },
                            {
                                "name": "get_ai_rankings",
                                "description": "AI ëª¨ë¸ ìˆœìœ„ ì¡°íšŒ",
                                "inputSchema": {
                                    "type": "object",
                                    "properties": {
                                        "benchmark": {"type": "string"}
                                    }
                                }
                            },
                            {
                                "name": "recommend_ai_for_task",
                                "description": "ì‘ì—…ì— ë§ëŠ” AI ì¶”ì²œ",
                                "inputSchema": {
                                    "type": "object",
                                    "properties": {
                                        "task": {"type": "string"},
                                        "budget": {"type": "string"},
                                        "priority": {"type": "string"}
                                    }
                                }
                            }
                        ]
                    }
                })
            
            elif body.get('method') == 'tools/call':
                # ë„êµ¬ ì‹¤í–‰
                tool_name = body.get('params', {}).get('name')
                arguments = body.get('params', {}).get('arguments', {})
                
                # ë„êµ¬ ì‹¤í–‰
                result = None
                if tool_name == 'search_ai_models':
                    result = await search_ai_models(**arguments)
                elif tool_name == 'search_ai_tools':
                    result = await search_ai_tools(**arguments)
                elif tool_name == 'get_latest_ai_news':
                    result = await get_latest_ai_news(**arguments)
                elif tool_name == 'get_ai_rankings':
                    result = await get_ai_rankings(**arguments)
                elif tool_name == 'recommend_ai_for_task':
                    result = await recommend_ai_for_task(**arguments)
                
                return JSONResponse({
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": str(result)
                            }
                        ]
                    }
                })
            
            # ê¸°íƒ€ ìš”ì²­
            return JSONResponse({
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "result": {}
            })
            
        except Exception as e:
            return JSONResponse({
                "jsonrpc": "2.0",
                "id": body.get("id", None),
                "error": {
                    "code": -32603,
                    "message": str(e)
                }
            }, status_code=500)
    
    async def health_check(request: Request):
        """Health check"""
        return JSONResponse({
            "service": "AI Recommender MCP",
            "status": "running",
            "version": "1.0.0",
            "tools": [
                "search_ai_models",
                "search_ai_tools",
                "get_latest_ai_news",
                "get_ai_rankings",
                "recommend_ai_for_task"
            ]
        })
    
    app = Starlette(
        routes=[
            Route("/", health_check, methods=["GET"]),
            Route("/sse", sse_endpoint, methods=["GET"]),
            Route("/message", message_endpoint, methods=["POST"]),
        ]
    )
    
    return app

# ==================== ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë“ˆ ë ˆë²¨) ====================
# Koyeb, uvicorn ë“±ì—ì„œ importí•  ìˆ˜ ìˆë„ë¡ ëª¨ë“ˆ ë ˆë²¨ì— ë°°ì¹˜
app = get_mcp_app()

# ==================== ë©”ì¸ ì‹¤í–‰ ====================

if __name__ == "__main__":
    import sys
    
    # HTTP ì„œë²„ ëª¨ë“œ (--http í”Œë˜ê·¸)
    if "--http" in sys.argv:
        print("ğŸš€ HTTP ì„œë²„ ëª¨ë“œ ì‹œì‘", file=sys.stderr)
        print("ğŸ“ http://localhost:8000 ì—ì„œ ì‹¤í–‰ ì¤‘", file=sys.stderr)
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8000)
    else:
        # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© - MCP Inspector stdio ì—°ê²°
        print("ğŸ”§ MCP stdio mode - Inspector ì—°ê²° ê°€ëŠ¥", file=sys.stderr)
        print("ğŸ“ ì‚¬ìš©ë²•: npx @modelcontextprotocol/inspector python main.py", file=sys.stderr)
        mcp.run()  # FastMCPì˜ ê¸°ë³¸ stdio ëª¨ë“œ