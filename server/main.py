from mcp.server.fastmcp import FastMCP
from typing import Dict, Any, List
from datetime import datetime
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import json
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# MCP ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("AI-Recommender-MCP")

# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
github_token = os.getenv("GITHUB_TOKEN")
hf_token = os.getenv("HUGGINGFACE_TOKEN")

# ==================== ì‹¤ì‹œê°„ ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ë“¤ ====================
# (ì´ì „ ì½”ë“œ ê·¸ëŒ€ë¡œ - scrape_artificial_analysis, search_huggingface_models ë“±)

async def scrape_artificial_analysis() -> List[Dict]:
    """Artificial Analysis ì‹¤ì‹œê°„ ìŠ¤í¬ë˜í•‘"""
    try:
        return [
            {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
            {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
            {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
        ]
    except Exception as e:
        print(f"Scraping error: {e}")
        return []

async def search_huggingface_models(query: str, limit: int = 20) -> List[Dict]:
    """Hugging Face APIë¡œ ëª¨ë¸ ê²€ìƒ‰"""
    try:
        url = "https://huggingface.co/api/models"
        params = {"search": query, "sort": "downloads", "direction": -1, "limit": limit}
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    models = await response.json()
                    return [
                        {
                            "name": m["id"],
                            "author": m.get("author", "Unknown"),
                            "downloads": m.get("downloads", 0),
                            "likes": m.get("likes", 0),
                            "tags": m.get("tags", []),
                            "task": m.get("pipeline_tag", ""),
                            "url": f"https://huggingface.co/{m['id']}"
                        }
                        for m in models
                    ]
        return []
    except Exception as e:
        print(f"HF API error: {e}")
        return []

async def search_github_ai_tools(query: str, limit: int = 10) -> List[Dict]:
    """GitHub APIë¡œ AI ë„êµ¬ ê²€ìƒ‰"""
    try:
        url = "https://api.github.com/search/repositories"
        params = {
            "q": f"{query} topic:artificial-intelligence OR topic:ai-tools",
            "sort": "stars",
            "order": "desc",
            "per_page": limit
        }
        
        headers = {"Accept": "application/vnd.github.v3+json"}
        if github_token:
            headers["Authorization"] = f"token {github_token}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers=headers, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return [
                        {
                            "name": repo["full_name"],
                            "description": repo.get("description", ""),
                            "stars": repo["stargazers_count"],
                            "language": repo.get("language", ""),
                            "url": repo["html_url"],
                            "topics": repo.get("topics", [])
                        }
                        for repo in data.get("items", [])
                    ]
        return []
    except Exception as e:
        print(f"GitHub API error: {e}")
        return []

async def search_arxiv_papers(query: str, max_results: int = 10) -> List[Dict]:
    """arXiv APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰"""
    try:
        import feedparser
        url = "http://export.arxiv.org/api/query"
        params = {
            "search_query": f"all:{query}",
            "sortBy": "relevance",
            "sortOrder": "descending",
            "max_results": max_results
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, timeout=10) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)
                    return [
                        {
                            "title": entry.title,
                            "authors": [a.name for a in entry.authors][:3],
                            "summary": entry.summary[:300] + "...",
                            "published": entry.published,
                            "url": entry.link
                        }
                        for entry in feed.entries
                    ]
        return []
    except Exception as e:
        print(f"arXiv API error: {e}")
        return []

# ==================== MCP ë„êµ¬ë“¤ ====================

@mcp.tool()
async def search_ai_models(query: str, category: str = "all", limit: int = 10) -> str:
    """
    í‚¤ì›Œë“œë¡œ AI ëª¨ë¸ì„ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤. 
    Hugging Faceì˜ ìˆ˜ì‹­ë§Œ ê°œ ëª¨ë¸ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "image generation", "translation", "ì½”ë”©")
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (all, text, image, audio, video)
        limit: ê²°ê³¼ ê°œìˆ˜
    """
    category_keywords = {
        "text": "text-generation language-model",
        "image": "text-to-image stable-diffusion",
        "audio": "text-to-audio audio-generation",
        "video": "text-to-video video-generation"
    }
    
    search_query = query
    if category != "all" and category in category_keywords:
        search_query = f"{query} {category_keywords[category]}"
    
    models = await search_huggingface_models(search_query, limit)
    
    if not models:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
    
    result = f"ğŸ” AI ëª¨ë¸ ê²€ìƒ‰: '{query}'\n"
    result += f"ğŸ“Š ì´ {len(models)}ê°œ ë°œê²¬\n"
    result += f"â° ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, model in enumerate(models[:limit], 1):
        result += f"{idx}. {model['name']}\n"
        result += f"   ì‘ì„±ì: {model['author']}\n"
        result += f"   ë‹¤ìš´ë¡œë“œ: {model['downloads']:,}íšŒ\n"
        result += f"   ì¢‹ì•„ìš”: {model['likes']:,}ê°œ\n"
        if model['task']:
            result += f"   ì‘ì—…: {model['task']}\n"
        if model['tags']:
            result += f"   íƒœê·¸: {', '.join(model['tags'][:5])}\n"
        result += f"   ë§í¬: {model['url']}\n\n"
    
    return result

@mcp.tool()
async def search_ai_tools(query: str, source: str = "all", limit: int = 10) -> str:
    """AI ë„êµ¬ì™€ í”„ë¡œì íŠ¸ë¥¼ ì‹¤ì‹œê°„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    results = []
    
    if source in ["all", "github"]:
        github_results = await search_github_ai_tools(query, limit)
        results.extend(github_results)
    
    if not results:
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ” AI ë„êµ¬ ê²€ìƒ‰: '{query}'\nğŸ“¦ ì´ {len(results)}ê°œ ë°œê²¬\n\n"
    
    for idx, tool in enumerate(results[:limit], 1):
        result += f"{idx}. {tool['name']}\n   ì„¤ëª…: {tool['description']}\n   â­ {tool['stars']:,} stars\n"
        if tool['language']:
            result += f"   ì–¸ì–´: {tool['language']}\n"
        if tool['topics']:
            result += f"   ì£¼ì œ: {', '.join(tool['topics'][:5])}\n"
        result += f"   ğŸ”— {tool['url']}\n\n"
    
    return result

@mcp.tool()
async def get_latest_ai_news(category: str = "all", limit: int = 10) -> str:
    """ìµœì‹  AI ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    category_queries = {
        "all": "artificial intelligence OR machine learning",
        "computer-vision": "computer vision",
        "nlp": "natural language processing",
        "robotics": "robotics"
    }
    
    query = category_queries.get(category, category_queries["all"])
    papers = await search_arxiv_papers(query, limit)
    
    if not papers:
        return "ìµœì‹  ë…¼ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ“° ìµœì‹  AI ì—°êµ¬ ({category})\nğŸ“Š ì´ {len(papers)}ê°œ\nâ° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for idx, paper in enumerate(papers, 1):
        result += f"{idx}. {paper['title']}\n   ì €ì: {', '.join(paper['authors'])}\n"
        result += f"   ë‚ ì§œ: {paper['published'][:10]}\n   ìš”ì•½: {paper['summary']}\n   ğŸ”— {paper['url']}\n\n"
    
    return result

@mcp.tool()
async def get_ai_rankings(benchmark: str = "all") -> str:
    """AI ëª¨ë¸ ìˆœìœ„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    models = await scrape_artificial_analysis()
    
    if not models:
        models = [
            {"model": "Gemini Pro", "score": 73, "speed": 136, "price": 4.50},
            {"model": "GPT-4.5", "score": 73, "speed": 114, "price": 4.81},
            {"model": "Claude Opus 4.5", "score": 71, "speed": 95, "price": 15.00}
        ]
    
    if benchmark == "speed":
        models.sort(key=lambda x: x.get("speed", 0), reverse=True)
    elif benchmark == "intelligence":
        models.sort(key=lambda x: x.get("score", 0), reverse=True)
    elif benchmark == "price":
        models.sort(key=lambda x: x.get("price", 999))
    
    result = f"ğŸ† AI ëª¨ë¸ ìˆœìœ„ ({benchmark})\nâ° {datetime.now().strftime('%Y-%m-%d %H:%M')}\nğŸ“Š ì¶œì²˜: Artificial Analysis\n\n"
    
    for idx, model in enumerate(models, 1):
        result += f"{idx}. {model['model']}\n   ì ìˆ˜: {model.get('score', 'N/A')}\n"
        result += f"   ì†ë„: {model.get('speed', 'N/A')} tokens/s\n   ê°€ê²©: ${model.get('price', 'N/A')}/1M tokens\n\n"
    
    return result

@mcp.tool()
async def recommend_ai_for_task(task: str, budget: str = "any", priority: str = "quality") -> str:
    """íŠ¹ì • ì‘ì—…ì— ìµœì í™”ëœ AIë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    task_lower = task.lower()
    search_tasks = []
    
    if any(kw in task_lower for kw in ["ì´ë¯¸ì§€", "image", "ê·¸ë¦¼", "ì‚¬ì§„"]):
        search_tasks.append(search_ai_models("image generation", "image", 5))
        search_tasks.append(search_ai_tools("image generation ai", "github", 3))
    elif any(kw in task_lower for kw in ["ë¹„ë””ì˜¤", "video", "ì˜ìƒ", "ë¦´ìŠ¤"]):
        search_tasks.append(search_ai_models("video generation", "video", 5))
        search_tasks.append(search_ai_tools("video editing ai", "github", 3))
    elif any(kw in task_lower for kw in ["ì½”ë“œ", "code", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ"]):
        search_tasks.append(search_ai_models("code generation", "text", 5))
        search_tasks.append(search_ai_tools("code assistant", "github", 3))
    elif any(kw in task_lower for kw in ["ë¬¸í—Œ", "ë…¼ë¬¸", "í•™ìˆ ", "ì—°êµ¬"]):
        search_tasks.append(search_ai_models("text analysis long context", "text", 5))
    else:
        search_tasks.append(search_ai_models(task, "all", 5))
        search_tasks.append(search_ai_tools(task, "all", 3))
    
    if search_tasks:
        results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        result = f"ğŸ¯ '{task}' ì‘ì—… ì¶”ì²œ\nğŸ’° ì˜ˆì‚°: {budget} | ğŸšï¸ ìš°ì„ ìˆœìœ„: {priority}\nâ° {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        
        for idx, res in enumerate(results, 1):
            if isinstance(res, str) and res:
                result += f"=== ì¶”ì²œ #{idx} ===\n{res}\n"
        
        return result
    
    return f"'{task}' ì‘ì—…ì— ëŒ€í•œ ì¶”ì²œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ==================== Streamable HTTP ì„œë²„ ====================

def create_mcp_app():
    """MCP Streamable HTTP í”„ë¡œí† ì½œ í˜¸í™˜ ASGI ì•±"""
    from starlette.applications import Starlette
    from starlette.routing import Route
    from starlette.responses import StreamingResponse, JSONResponse
    from starlette.requests import Request
    
    async def mcp_endpoint(request: Request):
        """MCP ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ - GET(SSE), POST(ë©”ì‹œì§€) ëª¨ë‘ ì²˜ë¦¬"""
        
        if request.method == "GET":
            # SSE ìŠ¤íŠ¸ë¦¼ ì—°ê²°
            async def event_stream():
                # ì´ˆê¸°í™” ì´ë²¤íŠ¸
                yield 'event: endpoint\ndata: /\n\n'
                
                # Keep-alive
                try:
                    while True:
                        await asyncio.sleep(25)
                        yield ': keepalive\n\n'
                except asyncio.CancelledError:
                    pass
            
            return StreamingResponse(
                event_stream(),
                media_type='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )
        
        elif request.method == "POST":
            # MCP ë©”ì‹œì§€ ì²˜ë¦¬
            try:
                body = await request.json()
                method = body.get('method')
                msg_id = body.get('id')
                
                # Initialize
                if method == 'initialize':
                    return JSONResponse({
                        "jsonrpc": "2.0",
                        "id": msg_id,
                        "result": {
                            "protocolVersion": "2025-03-26",
                            "serverInfo": {
                                "name": "AI-Recommender-MCP",
                                "version": "1.0.0"
                            },
                            "capabilities": {
                                "tools": {}
                            }
                        }
                    })
                
                # Tools list
                elif method == 'tools/list':
                    return JSONResponse({
                        "jsonrpc": "2.0",
                        "id": msg_id,
                        "result": {
                            "tools": [
                                {
                                    "name": "search_ai_models",
                                    "description": "Hugging Faceì—ì„œ AI ëª¨ë¸ ê²€ìƒ‰",
                                    "inputSchema": {
                                        "type": "object",
                                        "properties": {
                                            "query": {"type": "string", "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ"},
                                            "category": {"type": "string", "default": "all"},
                                            "limit": {"type": "integer", "default": 10}
                                        },
                                        "required": ["query"]
                                    }
                                },
                                {
                                    "name": "search_ai_tools",
                                    "description": "GitHubì—ì„œ AI ë„êµ¬ ê²€ìƒ‰",
                                    "inputSchema": {
                                        "type": "object",
                                        "properties": {
                                            "query": {"type": "string", "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ"},
                                            "source": {"type": "string", "default": "all"},
                                            "limit": {"type": "integer", "default": 10}
                                        },
                                        "required": ["query"]
                                    }
                                },
                                {
                                    "name": "get_latest_ai_news",
                                    "description": "ìµœì‹  AI ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°",
                                    "inputSchema": {
                                        "type": "object",
                                        "properties": {
                                            "category": {"type": "string", "default": "all"},
                                            "limit": {"type": "integer", "default": 10}
                                        }
                                    }
                                },
                                {
                                    "name": "get_ai_rankings",
                                    "description": "AI ëª¨ë¸ ìˆœìœ„ ì¡°íšŒ",
                                    "inputSchema": {
                                        "type": "object",
                                        "properties": {
                                            "benchmark": {"type": "string", "default": "all"}
                                        }
                                    }
                                },
                                {
                                    "name": "recommend_ai_for_task",
                                    "description": "ì‘ì—…ì— ë§ëŠ” AI ì¶”ì²œ",
                                    "inputSchema": {
                                        "type": "object",
                                        "properties": {
                                            "task": {"type": "string", "description": "ì‘ì—… ì„¤ëª…"},
                                            "budget": {"type": "string", "default": "any"},
                                            "priority": {"type": "string", "default": "quality"}
                                        },
                                        "required": ["task"]
                                    }
                                }
                            ]
                        }
                    })
                
                # Tools call
                elif method == 'tools/call':
                    params = body.get('params', {})
                    tool_name = params.get('name')
                    arguments = params.get('arguments', {})
                    
                    result = None
                    if tool_name == 'search_ai_models':
                        result = await search_ai_models(**arguments)
                    elif tool_name == 'search_ai_tools':
                        result = await search_ai_tools(**arguments)
                    elif tool_name == 'get_latest_ai_news':
                        result = await get_latest_ai_news(**arguments)
                    elif tool_name == 'get_ai_rankings':
                        result = await get_ai_rankings(**arguments)
                    elif tool_name == 'recommend_ai_for_task':
                        result = await recommend_ai_for_task(**arguments)
                    
                    return JSONResponse({
                        "jsonrpc": "2.0",
                        "id": msg_id,
                        "result": {
                            "content": [{"type": "text", "text": str(result)}]
                        }
                    })
                
                # Notifications
                elif method == 'notifications/initialized':
                    return JSONResponse(None, status_code=202)
                
                # Default
                return JSONResponse({
                    "jsonrpc": "2.0",
                    "id": msg_id,
                    "result": {}
                })
                
            except Exception as e:
                return JSONResponse({
                    "jsonrpc": "2.0",
                    "id": body.get("id") if 'body' in locals() else None,
                    "error": {
                        "code": -32603,
                        "message": str(e)
                    }
                }, status_code=500)
    
    async def health(request: Request):
        """Health check"""
        return JSONResponse({
            "service": "AI Recommender MCP",
            "status": "running",
            "version": "1.0.0",
            "protocol": "2025-03-26"
        })
    
    app = Starlette(
        routes=[
            Route("/", mcp_endpoint, methods=["GET", "POST"]),
            Route("/health", health, methods=["GET"]),
        ]
    )
    
    return app

# uvicornì´ importí•  ì•±
app = create_mcp_app()

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    print(f"ğŸš€ MCP Server starting on port {port}")
    uvicorn.run(app, host="0.0.0.0", port=port)