import sys
from pathlib import Path
from typing import Dict, Any, Optional
import os

# =========================
# PYTHONPATH ë³´ì • (í•„ìˆ˜)
# =========================
BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR))

# =========================
# MCP
# =========================
from mcp.server.fastmcp import FastMCP

from tools import (
    AINewsCollector,
    get_cached_news,
    AIAgentCatalog,
)

from tools.api_integrations import (
    get_trending_ai_models,
    search_models,
    get_latest_ai_research,
    get_all_updates,
)

from tools.realtime_collector import (
    get_realtime_rankings,
    recommend_model_for_task,
)

# MCP ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("AI Recommender MCP")

agent_catalog = AIAgentCatalog()

# =========================
# MCP Tools
# =========================

@mcp.tool()
def list_ai_agents(category: str = "all", subcategory: Optional[str] = None) -> Dict[str, Any]:
    """AI Agent ëª©ë¡ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return agent_catalog.list_agents(category, subcategory)

@mcp.tool()
def search_ai_agents(query: str) -> Dict[str, Any]:
    """í‚¤ì›Œë“œë¡œ AI Agentë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return agent_catalog.search_agents(query)

@mcp.tool()
def recommend_ai_agent(task: str, experience_level: str = "intermediate", budget: str = "any") -> Dict[str, Any]:
    """íŠ¹ì • ì‘ì—…ì— ë§ëŠ” AI Agentë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    return agent_catalog.recommend_for_task(task, experience_level, budget)

@mcp.tool()
async def get_ai_news(category: str = "all", limit: int = 10):
    """ìµœì‹  AI ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_cached_news(category, limit)

@mcp.tool()
async def get_trending_models(limit: int = 10):
    """íŠ¸ë Œë”© AI ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_trending_ai_models(limit)

@mcp.tool()
async def search_model_for_task(task: str):
    """ì‘ì—…ì— ë§ëŠ” ëª¨ë¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return await search_models(task)

@mcp.tool()
async def latest_ai_research(max_results: int = 10):
    """ìµœì‹  AI ì—°êµ¬ ë…¼ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_latest_ai_research(max_results)

@mcp.tool()
async def ai_overview():
    """AI ìƒíƒœê³„ ì¢…í•© ì—…ë°ì´íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_all_updates()

@mcp.tool()
async def realtime_model_rankings(benchmark: str = "artificial-analysis"):
    """ì‹¤ì‹œê°„ AI ëª¨ë¸ ìˆœìœ„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return await get_realtime_rankings(benchmark)

@mcp.tool()
async def recommend_model(task: str):
    """ì‘ì—…ì— ìµœì í™”ëœ ëª¨ë¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    return await recommend_model_for_task(task)

def get_mcp_app():
    from starlette.applications import Starlette
    from starlette.routing import Route
    from starlette.responses import JSONResponse
    from starlette.requests import Request
    
    async def health_check(request: Request):
        return JSONResponse({"status": "ok", "service": "AI Recommender MCP"})
    
    async def root_handler(request: Request):
        if request.method == "GET":
            return await health_check(request)
        elif request.method == "POST":
            # MCP ë©”ì‹œì§€ ì²˜ë¦¬
            body = await request.json()
            return JSONResponse({
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "result": {
                    "tools": [
                        {"name": "list_ai_agents", "description": "AI Agent ëª©ë¡ ì¡°íšŒ"},
                        {"name": "search_ai_agents", "description": "AI Agent ê²€ìƒ‰"},
                        {"name": "recommend_ai_agent", "description": "ì‘ì—…ì— ë§ëŠ” Agent ì¶”ì²œ"},
                        {"name": "get_ai_news", "description": "ìµœì‹  AI ë‰´ìŠ¤"},
                        {"name": "get_trending_models", "description": "íŠ¸ë Œë”© ëª¨ë¸"},
                        {"name": "search_model_for_task", "description": "ì‘ì—…ìš© ëª¨ë¸ ê²€ìƒ‰"},
                        {"name": "latest_ai_research", "description": "ìµœì‹  AI ì—°êµ¬"},
                        {"name": "ai_overview", "description": "AI ìƒíƒœê³„ ì—…ë°ì´íŠ¸"},
                        {"name": "realtime_model_rankings", "description": "ì‹¤ì‹œê°„ ëª¨ë¸ ìˆœìœ„"},
                        {"name": "recommend_model", "description": "ëª¨ë¸ ì¶”ì²œ"}
                    ]
                }
            })
        return JSONResponse({"error": "Method not allowed"}, status_code=405)
    
    return Starlette(
        routes=[
            Route("/", root_handler, methods=["GET", "POST"]),
        ]
    )

app = get_mcp_app()

# =========================
# Run
# =========================
if __name__ == "__main__":
    import uvicorn
    
    mode = os.getenv("MCP_MODE", "stdio")
    
    print(f"ğŸ”¥ MAIN BLOCK EXECUTING", file=sys.stderr)
    print(f"ğŸš€ Starting MCP Server in {mode} mode", file=sys.stderr)
    
    if mode == "sse":
        port = int(os.getenv("PORT", 8000))
        host = "0.0.0.0"
        
        print(f"ğŸ“¡ SSE server at http://{host}:{port}", file=sys.stderr)
        
        # uvicorn íŒ¨ì¹˜ ë°©ì‹ â­
        original_run = uvicorn.run
        
        def patched_run(app, **kwargs):
            kwargs['host'] = host
            kwargs['port'] = port
            return original_run(app, **kwargs)
        
        uvicorn.run = patched_run
        
        # ì´ì œ mcp.run() í˜¸ì¶œí•˜ë©´ íŒ¨ì¹˜ëœ uvicorn ì‚¬ìš©
        mcp.run(transport="streamable-http")